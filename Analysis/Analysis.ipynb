{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5_model_lt_20_5.pth.tar',\n",
       " '8_model_lt_20_27.pth.tar',\n",
       " '8_model_lt_20_12.pth.tar',\n",
       " '0_model_lt_20_15.pth.tar',\n",
       " '4_model_lt_20_16.pth.tar',\n",
       " '1_model_lt_20_19.pth.tar',\n",
       " '9_model_lt_20_3.pth.tar',\n",
       " '9_model_lt_20_30.pth.tar',\n",
       " '7_model_lt_20_15.pth.tar',\n",
       " '1_model_lt_20_1.pth.tar',\n",
       " '8_model_lt_20_6.pth.tar',\n",
       " '1_model_lt_20_27.pth.tar',\n",
       " '2_model_lt_20_23.pth.tar',\n",
       " '7_model_lt_20_1.pth.tar',\n",
       " '3_model_lt_20_16.pth.tar',\n",
       " '0_model_lt_20_26.pth.tar',\n",
       " '5_model_lt_20_6.pth.tar',\n",
       " '1_model_lt_20_4.pth.tar',\n",
       " '5_model_lt_20_1.pth.tar',\n",
       " '6_model_lt_20_0.pth.tar',\n",
       " '1_model_lt_20_0.pth.tar',\n",
       " '2_model_lt_20_4.pth.tar',\n",
       " '7_model_lt_20_8.pth.tar',\n",
       " '4_model_lt_20_3.pth.tar',\n",
       " '7_model_lt_20_4.pth.tar',\n",
       " '5_model_lt_20_19.pth.tar',\n",
       " '0_model_lt_20_2.pth.tar',\n",
       " '0_model_lt_20_7.pth.tar',\n",
       " '7_model_lt_20_0.pth.tar',\n",
       " '5_model_lt_20_0.pth.tar',\n",
       " '3_model_lt_20_2.pth.tar',\n",
       " '9_model_lt_20_18.pth.tar',\n",
       " '8_model_lt_20_1.pth.tar',\n",
       " '5_model_lt_20_25.pth.tar',\n",
       " '5_model_lt_20_2.pth.tar',\n",
       " '2_model_lt_20_2.pth.tar',\n",
       " '2_model_lt_20_5.pth.tar',\n",
       " '2_model_lt_20_1.pth.tar',\n",
       " '4_model_lt_20_1.pth.tar',\n",
       " '0_model_lt_20_24.pth.tar',\n",
       " '2_model_lt_20_3.pth.tar',\n",
       " '3_model_lt_20_0.pth.tar',\n",
       " '5_model_lt_20_3.pth.tar',\n",
       " '9_model_lt_20_7.pth.tar',\n",
       " '9_model_lt_20_14.pth.tar',\n",
       " '4_model_lt_20_2.pth.tar',\n",
       " '6_model_lt_20_5.pth.tar',\n",
       " '0_model_lt_20_3.pth.tar',\n",
       " '2_model_lt_20_12.pth.tar',\n",
       " '2_model_lt_20_19.pth.tar',\n",
       " '5_model_lt_20_8.pth.tar',\n",
       " '9_model_lt_20_4.pth.tar',\n",
       " '9_model_lt_20_23.pth.tar',\n",
       " '0_model_lt_20_4.pth.tar',\n",
       " '3_model_lt_20_6.pth.tar',\n",
       " '6_model_lt_20_3.pth.tar',\n",
       " '0_model_lt_20_16.pth.tar',\n",
       " '4_model_lt_20_0.pth.tar',\n",
       " '9_model_lt_20_9.pth.tar',\n",
       " '6_model_lt_20_14.pth.tar',\n",
       " '2_model_lt_20_17.pth.tar',\n",
       " '7_model_lt_20_11.pth.tar',\n",
       " '8_model_lt_20_3.pth.tar',\n",
       " '2_model_lt_20_36.pth.tar',\n",
       " '0_model_lt_20_12.pth.tar',\n",
       " '7_model_lt_20_42.pth.tar',\n",
       " '8_model_lt_20_2.pth.tar',\n",
       " '6_model_lt_20_32.pth.tar',\n",
       " '8_model_lt_20_26.pth.tar',\n",
       " '1_model_lt_20_2.pth.tar',\n",
       " '1_model_lt_20_3.pth.tar',\n",
       " '4_model_lt_20_4.pth.tar',\n",
       " '4_model_lt_20_8.pth.tar',\n",
       " '7_model_lt_20_5.pth.tar',\n",
       " '6_model_lt_20_15.pth.tar',\n",
       " '3_model_lt_20_33.pth.tar',\n",
       " '2_model_lt_20_10.pth.tar',\n",
       " '7_model_lt_20_34.pth.tar',\n",
       " '6_model_lt_20_11.pth.tar',\n",
       " '1_model_lt_20_17.pth.tar',\n",
       " '3_model_lt_20_7.pth.tar',\n",
       " '7_model_lt_20_13.pth.tar',\n",
       " '7_model_lt_20_9.pth.tar',\n",
       " '8_model_lt_20_11.pth.tar',\n",
       " '8_model_lt_20_9.pth.tar',\n",
       " '1_model_lt_20_5.pth.tar',\n",
       " '9_model_lt_20_2.pth.tar',\n",
       " '0_model_lt_20_22.pth.tar',\n",
       " '3_model_lt_20_1.pth.tar',\n",
       " '3_model_lt_20_5.pth.tar',\n",
       " '8_model_lt_20_19.pth.tar',\n",
       " '7_model_lt_20_2.pth.tar',\n",
       " '8_model_lt_20_0.pth.tar',\n",
       " '5_model_lt_20_26.pth.tar',\n",
       " '3_model_lt_20_12.pth.tar',\n",
       " '6_model_lt_20_36.pth.tar',\n",
       " '9_model_lt_20_1.pth.tar',\n",
       " '0_model_lt_20_1.pth.tar',\n",
       " '8_model_lt_20_8.pth.tar',\n",
       " '3_model_lt_20_45.pth.tar',\n",
       " '6_model_lt_20_20.pth.tar',\n",
       " '5_model_lt_20_9.pth.tar',\n",
       " '0_model_lt_20_47.pth.tar',\n",
       " '5_model_lt_20_24.pth.tar',\n",
       " '9_model_lt_20_0.pth.tar',\n",
       " '7_model_lt_20_3.pth.tar',\n",
       " '3_model_lt_20_4.pth.tar',\n",
       " '6_model_lt_20_4.pth.tar',\n",
       " '2_model_lt_20_27.pth.tar',\n",
       " '0_model_lt_20_0.pth.tar',\n",
       " '9_model_lt_20_8.pth.tar',\n",
       " '6_model_lt_20_2.pth.tar',\n",
       " '2_model_lt_20_9.pth.tar',\n",
       " '1_model_lt_20_12.pth.tar',\n",
       " '6_model_lt_20_1.pth.tar',\n",
       " '9_model_lt_20_19.pth.tar',\n",
       " '2_model_lt_20_0.pth.tar',\n",
       " '3_model_lt_20_9.pth.tar']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/home/udit/programs/LTHT/data/saves/fc1/mnist/0/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Cython in /home/udit/anaconda3/envs/ltht/lib/python3.6/site-packages (0.29.15)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install Cython "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: persim in /home/udit/anaconda3/envs/ltht/lib/python3.6/site-packages (0.1.2)\n",
      "Requirement already satisfied: Ripser in /home/udit/anaconda3/envs/ltht/lib/python3.6/site-packages (0.4.1)\n",
      "Requirement already satisfied: networkx in /home/udit/anaconda3/envs/ltht/lib/python3.6/site-packages (2.4)\n",
      "Requirement already satisfied: scipy in /home/udit/anaconda3/envs/ltht/lib/python3.6/site-packages (from persim) (1.3.1)\n",
      "Requirement already satisfied: matplotlib in /home/udit/anaconda3/envs/ltht/lib/python3.6/site-packages (from persim) (3.1.1)\n",
      "Requirement already satisfied: scikit-learn in /home/udit/anaconda3/envs/ltht/lib/python3.6/site-packages (from persim) (0.22.2.post1)\n",
      "Requirement already satisfied: numpy in /home/udit/anaconda3/envs/ltht/lib/python3.6/site-packages (from persim) (1.17.2)\n",
      "Requirement already satisfied: hopcroftkarp in /home/udit/anaconda3/envs/ltht/lib/python3.6/site-packages (from persim) (1.2.5)\n",
      "Requirement already satisfied: Cython in /home/udit/anaconda3/envs/ltht/lib/python3.6/site-packages (from Ripser) (0.29.15)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/udit/anaconda3/envs/ltht/lib/python3.6/site-packages (from networkx) (4.4.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/udit/anaconda3/envs/ltht/lib/python3.6/site-packages (from matplotlib->persim) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/udit/anaconda3/envs/ltht/lib/python3.6/site-packages (from matplotlib->persim) (2.8.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/udit/anaconda3/envs/ltht/lib/python3.6/site-packages (from matplotlib->persim) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/udit/anaconda3/envs/ltht/lib/python3.6/site-packages (from matplotlib->persim) (0.10.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/udit/anaconda3/envs/ltht/lib/python3.6/site-packages (from scikit-learn->persim) (0.14.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/udit/anaconda3/envs/ltht/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib->persim) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/udit/anaconda3/envs/ltht/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->persim) (46.0.0.post20200309)\n"
     ]
    }
   ],
   "source": [
    "!pip install persim Ripser networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '/home/udit/programs/LTHT/data/saves/' # need absolute root dir location\n",
    "model_list = ['fc1', 'resnet18', 'vgg16']\n",
    "dataset_list = ['mnist', 'cifar10']\n",
    "random_seed = ['0', '42', '1337']\n",
    "#msk_pct = 90 # prune percentage for LT network\n",
    "#model_loc0 = 'saves/{}/{}/{}/0_model_lt.pth.tar'.format(model_name, dataset_name, random_seed) # location of saved, un-pruned model \n",
    "#model_loc1 = 'saves/{}/{}/4_model_lt.pth.tar'.format(model_name, dataset_name) # location of saved, pruned model (after 1 prune iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_training_file_for_pruning_iteration(pruning_iteration, trained_files):\n",
    "    best_epoch = 0\n",
    "    best_file = \"\"\n",
    "    for file in trained_files:\n",
    "        if (file.startswith(str(pruning_iteration)+\"_\")):\n",
    "            file_name = file.split('.')[0]\n",
    "            curr_epoch = int(file_name.split('_')[-1])\n",
    "            if (best_epoch < curr_epoch):\n",
    "                best_epoch = curr_epoch\n",
    "                best_file = file\n",
    "    return best_file\n",
    "\n",
    "def get_best_training_files_in_dir(curr_dir):\n",
    "    best_model_per_pruning_it_list = []\n",
    "    model_trained_files = sorted(os.listdir(curr_dir))\n",
    "    pruning_iterations_done = []\n",
    "    for file in model_trained_files:\n",
    "        curr_pruning_iteration = file.split('_')[0]\n",
    "        if curr_pruning_iteration not in pruning_iterations_done:\n",
    "            best_training_file = get_best_training_file_for_pruning_iteration(curr_pruning_iteration, model_trained_files)\n",
    "            if (len(best_training_file) != 0):\n",
    "                best_model_per_pruning_it_list.append(best_training_file)\n",
    "            pruning_iterations_done.append(curr_pruning_iteration)\n",
    "    return best_model_per_pruning_it_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/udit/programs/LTHT/data/saves/fc1/mnist/0/\n",
      "/home/udit/programs/LTHT/data/saves/fc1/mnist/42/\n",
      "/home/udit/programs/LTHT/data/saves/fc1/mnist/1337/\n",
      "/home/udit/programs/LTHT/data/saves/resnet18/cifar10/0/\n",
      "/home/udit/programs/LTHT/data/saves/resnet18/cifar10/42/\n",
      "/home/udit/programs/LTHT/data/saves/resnet18/cifar10/1337/\n",
      "/home/udit/programs/LTHT/data/saves/vgg16/cifar10/0/\n",
      "/home/udit/programs/LTHT/data/saves/vgg16/cifar10/42/\n",
      "/home/udit/programs/LTHT/data/saves/vgg16/cifar10/1337/\n"
     ]
    }
   ],
   "source": [
    "for model in model_list:\n",
    "    for dataset in dataset_list:\n",
    "        for seed in random_seed:\n",
    "            model_dataset_seed_dir = ROOT_DIR + \"{}/{}/{}/\".format(model, dataset, seed)\n",
    "            if (os.path.isdir(model_dataset_seed_dir)):\n",
    "                print(model_dataset_seed_dir)\n",
    "                best_model_per_pruning_it_list = get_best_training_files_in_dir(model_dataset_seed_dir)\n",
    "                compute_homology(model_dataset_seed_dir, best_model_per_pruning_it_list)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute homology per model-dataset-seed\n",
    "def compute_homology(root_dir, file_list):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import persim # see persim.scikit-tda.org\n",
    "from ripser import ripser # see ripser.scikit-tda.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# primary function for translating NN to networkx graph. \n",
    "def to_directed_networkx(params, layer_names=None):\n",
    "    '''primary function for translating FCNN to networkx graph. \n",
    "    Gives node a name corresponding to its layer and location in \n",
    "    parameter matrix. Weights edges to match notion of \"distance\"\n",
    "    matrix for nodes. \n",
    "    \n",
    "    params (list): list of FC weight matrices in numpy format.\n",
    "    layer_names (optional): list of layer names to be associated to each node\n",
    "    (defaults to integer layer number).\n",
    "    \n",
    "    returns: networkx DiGraph.\n",
    "    '''\n",
    "    if layer_names is None:\n",
    "        layer_names = [i for i in range(len(params))]\n",
    "    G = nx.DiGraph()\n",
    "    for i in range(len(params)):\n",
    "        layer_name = layer_names[i]\n",
    "        p = scipy.sparse.coo_matrix(params[i].T)\n",
    "        for i,j,v in zip(p.row, p.col, p.data):\n",
    "            if v != 0:\n",
    "                G.add_edge(str(layer_name)+'_'+str(i),str(layer_name+1)+'_'+str(j),weight=np.abs(1/1+v))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'archs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2c3757fc8cc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import torch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/udit/programs/LTHT/data/saves/fc1/mnist/0/0_model_lt_20_47.pth.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# params = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# for name, param in model.named_parameters():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     if 'weight' in name:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ltht/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ltht/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'archs'"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "model = torch.load('/home/udit/programs/LTHT/data/saves/fc1/mnist/0/0_model_lt_20_47.pth.tar')\n",
    "# params = []\n",
    "# for name, param in model.named_parameters():\n",
    "#     if 'weight' in name:\n",
    "#         pnum = param.data.cpu().numpy()\n",
    "#         print('Parameter Shape: ', pnum.shape)\n",
    "#         params.append(pnum)\n",
    "        \n",
    "# G = to_directed_networkx(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
