{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load compute_homology.py\n",
    "import networkx as nx\n",
    "import torch\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import persim  # see persim.scikit-tda.org\n",
    "from ripser import ripser  # see ripser.scikit-tda.org\n",
    "\n",
    "from archs.mnist.fc1 import fc1 as fc1_mnist\n",
    "from archs.cifar10.fc1 import fc1 as fc1_cifar10\n",
    "\n",
    "from archs.mnist.AlexNet import AlexNet as AlexNet_mnist\n",
    "from archs.mnist.AlexNet import AlexNet_nmp as AlexNet_nmp_mnist\n",
    "from archs.cifar10.AlexNet import AlexNet as AlexNet_cifar10\n",
    "from archs.cifar10.AlexNet import AlexNet_nmp as AlexNet_nmp_cifar10\n",
    "\n",
    "from archs.mnist.LeNet5 import LeNet5 as LeNet5_mnist\n",
    "from archs.mnist.LeNet5 import LeNet5_nmp as LeNet5_nmp_mnist\n",
    "from archs.cifar10.LeNet5 import LeNet5 as LeNet5_cifar10\n",
    "from archs.cifar10.LeNet5 import LeNet5_nmp as LeNet5_nmp_cifar10\n",
    "\n",
    "from archs.mnist.resnet import resnet18 as resnet18_mnist\n",
    "from archs.mnist.resnet_nmp import resnet18 as resnet18_nmp_mnist\n",
    "from archs.cifar10.resnet import resnet18 as resnet18_cifar10\n",
    "from archs.cifar10.resnet_nmp import resnet18 as resnet18_nmp_cifar10\n",
    "\n",
    "from nn_homology import nn_graph\n",
    "import argparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_graph_dict = {}\n",
    "\n",
    "def get_model_param_info(model_name, dataset):\n",
    "    model_param = {\n",
    "        \"fc1_mnist\": fc1_mnist,\n",
    "        \"fc1_cifar10\": fc1_cifar10,\n",
    "\n",
    "        \"alexnet_mnist\": AlexNet_mnist,\n",
    "        \"alexnet_nmp_mnist\": AlexNet_nmp_mnist,\n",
    "        \"alexnet_cifar10\": AlexNet_cifar10,\n",
    "        \"alexnet_nmp_cifar10\": AlexNet_nmp_cifar10,\n",
    "\n",
    "        \"lenet5_mnist\": AlexNet_mnist,\n",
    "        \"lenet5_nmp_mnist\": LeNet5_nmp_mnist,\n",
    "        \"lenet5_cifar10\": LeNet5_cifar10,\n",
    "        \"lenet5_nmp_cifar10\": LeNet5_nmp_cifar10,\n",
    "\n",
    "        \"resnet18_mnist\": resnet18_mnist,\n",
    "        \"resnet18_nmp_mnist\": resnet18_nmp_mnist,\n",
    "        \"resnet18_cifar10\": resnet18_cifar10,\n",
    "        \"resnet18_nmp_cifar10\": resnet18_nmp_cifar10\n",
    "    }\n",
    "    architecture = model_name + \"_\" + dataset\n",
    "    print(\"Getting parameters for: \", architecture)\n",
    "    param_info = model_param[architecture]().param_info\n",
    "    return param_info\n",
    "\n",
    "\n",
    "def compute_homology(model, dataset, root_dir):\n",
    "    for listed_file in sorted(os.listdir(root_dir)):\n",
    "        if (listed_file[0].isdigit()):\n",
    "            print(\"epoch: \", listed_file)\n",
    "            if listed_file != \".ipynb_checkpoints\":\n",
    "                best_model_per_pruning_it_location = root_dir + listed_file + \"/\" + \"model_lt_20.pth.tar\"\n",
    "                # print(best_model_per_pruning_it_location)\n",
    "                if (os.path.isfile(best_model_per_pruning_it_location)):\n",
    "                    computer_per_model_homology(model, dataset, root_dir, listed_file,\n",
    "                                                best_model_per_pruning_it_location)\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "def computer_per_model_homology(model_name, dataset, root_dir, epoch, model_location):\n",
    "    rips_pickle_dir = root_dir + \"pickle/\"\n",
    "    # print(rips_pickle_dir)\n",
    "    persim_image_dir = root_dir + \"persim/\"\n",
    "    # print(persim_image_dir)\n",
    "\n",
    "    model = torch.load(model_location)\n",
    "    if dataset == 'mnist':\n",
    "        input_dim = (1, 1, 28, 28)\n",
    "    elif dataset == 'cifar10':\n",
    "        input_dim = (1, 3, 32, 32)\n",
    "\n",
    "    param_info = get_model_param_info(model_name, dataset)\n",
    "\n",
    "    architecture = model_name + \"_\" + dataset\n",
    "    if (architecture not in model_graph_dict) or (epoch == 0):\n",
    "        print((\"Architecture: {} not found, creating\").format(architecture))\n",
    "        NNG = nn_graph.NNGraph()\n",
    "        NNG.parameter_graph(model, param_info, input_dim, ignore_zeros=True)\n",
    "        model_graph_dict[architecture] = NNG\n",
    "    else:\n",
    "        print((\"Architecture: {} found, loading ... \").format(architecture))\n",
    "        NNG = model_graph_dict[architecture]\n",
    "        NNG.update_adjacency(model)\n",
    "\n",
    "    rips = ripser(scipy.sparse.csr_matrix(NNG.get_adjacency()), distance_matrix=True, maxdim=2, do_cocycles=True)\n",
    "    # root_dir contains something in the format of:\n",
    "    # /home/udit/programs/LTHT/remote_data/saves/alexnet_nmp/mnist/0/\n",
    "\n",
    "    if not (os.path.isdir(rips_pickle_dir)):\n",
    "        os.mkdir(rips_pickle_dir)\n",
    "    rips_file = rips_pickle_dir + epoch\n",
    "    rips_pickle = open(rips_file + \".pickle\", \"wb\")\n",
    "    pickle.dump(rips, rips_pickle)\n",
    "    rips_pickle.close()\n",
    "\n",
    "    # save ripser file as pickle\n",
    "    persim.plot_diagrams(rips['dgms'])\n",
    "\n",
    "    if not (os.path.isdir(persim_image_dir)):\n",
    "        os.mkdir(persim_image_dir)\n",
    "    persim_plot_file = persim_image_dir + epoch\n",
    "    plt.savefig(persim_plot_file + \".jpg\")\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    ROOT_DIR = args.root_dir\n",
    "    model_name = args.model_name\n",
    "    dataset = args.dataset\n",
    "    seed = args.seed\n",
    "\n",
    "    model_dataset_seed_dir = ROOT_DIR + \"{}/{}/{}/\".format(model_name, dataset, seed)\n",
    "    print(\"In: \", model_dataset_seed_dir)\n",
    "\n",
    "    if (os.path.isdir(model_dataset_seed_dir)):\n",
    "        compute_homology(model_name, dataset, model_dataset_seed_dir)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser()\n",
    "\n",
    "#     parser.add_argument(\"--root_dir\", default=\"/home/udit/programs/LTHT/data/saves/\", type=str)\n",
    "#     parser.add_argument(\"--model_name\", default='fc1', type=str)\n",
    "#     parser.add_argument(\"--dataset\", default='mnist', type=str)\n",
    "#     parser.add_argument(\"--seed\", default='0', type=str)\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "#     print(args)\n",
    "#     main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/udit/programs/LTHT/LTHT'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROOT_DIR = '/home/udit/programs/LTHT/data/saves/' # need absolute root dir location\n",
    "ROOT_DIR = '/home/udit/programs/LTHT/remote_data/saves/' # need absolute root dir location\n",
    "# model_list = ['alexnet_nmp', 'fc1', 'lenet5_nmp', 'resnet18', 'resnet18_nmp', 'vgg16']\n",
    "model_list = ['lenet5_nmp'] #, 'fc1', 'lenet5_nmp', 'alexnet_nmp']\n",
    "dataset_list = ['mnist', 'cifar10']\n",
    "random_seed = ['0', '42', '1337']\n",
    "# model_graph_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenet5_nmp\n",
      "mnist\n",
      "0\n",
      "epoch:  0\n",
      "Getting parameters for:  lenet5_nmp_mnist\n",
      "Architecture: lenet5_nmp_mnist not found, creating\n",
      "Layer: Conv1\n",
      "Layer: Conv2\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_list:\n",
    "    print(model_name)\n",
    "    for dataset in dataset_list:\n",
    "        print(dataset)\n",
    "        for seed in random_seed:\n",
    "            print(seed)\n",
    "            model_dataset_seed_dir = ROOT_DIR + \"{}/{}/{}/\".format(model_name, dataset, seed)\n",
    "            if (os.path.isdir(model_dataset_seed_dir)):\n",
    "                compute_homology(model_name, dataset, model_dataset_seed_dir)\n",
    "            break\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.pickle 9.pickle\n",
      "CPU times: user 56.2 s, sys: 35.8 ms, total: 56.2 s\n",
      "Wall time: 56.2 s\n",
      "Bottleneck Distance: 0.09660559892654419\n"
     ]
    }
   ],
   "source": [
    "rips_dir = \"/home/udit/programs/LTHT/data/saves/fc1/mnist/0/pickle/\"\n",
    "for file1 in os.listdir(rips_dir):\n",
    "    if file1[0].isdigit():\n",
    "        prune_iteration1 = file1[0]\n",
    "        rips1 = pickle.load(open(rips_dir+file1, 'rb'))\n",
    "        for file2 in os.listdir(rips_dir):\n",
    "            if file2[0].isdigit() and file1 != file2:\n",
    "                print(file1, file2)\n",
    "                prune_iteration2 = file2[0]\n",
    "                rips2 = pickle.load(open(rips_dir+file2, 'rb'))\n",
    "                %time distance_bottleneck, (matching, D) = persim.bottleneck(rips1['dgms'][0], rips2['dgms'][0], matching=True)\n",
    "#                 %time persim.bottleneck_matching(rips1['dgms'][0], rips2['dgms'][0], matching, D, labels=['FC $H_0$', 'LT $H_0$'])\n",
    "                print('Bottleneck Distance: {}'.format(distance_bottleneck))\n",
    "                break\n",
    "    break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
