{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "from nn_homology import nn_graph\n",
    "import dionysus as dion\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.sparse.csgraph import maximum_flow\n",
    "\n",
    "import persim # see persim.scikit-tda.org\n",
    "from ripser import ripser # see ripser.scikit-tda.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global-like variable definitions.\n",
    "model_name = 'resnet18'\n",
    "dataset_name = 'cifar10'\n",
    "data_location = '../data' # location of training data (MNIST, FashionMNIST, CIFAR, etc.)\n",
    "seeds = [0]\n",
    "model_loc0 = 'saves/{}/{}/{}/prune_all/global/0/model_lt_20.pth.tar' # location of saved, un-pruned model \n",
    "input_size = (1,3,32,32)\n",
    "from archs.cifar10.resnet import resnet18 as Mc\n",
    "isd_loc = 'saves/{}/{}/{}/prune_all/global/initial_state_dict_lt.pth.tar'\n",
    "percentile = 85\n",
    "percentile_filtration = True\n",
    "\n",
    "epochs = 5\n",
    "# prune_percents = np.flip([80,90,95,98,99,99.5,99.7,99.8,99.9,100])\n",
    "prune_percents = 100-np.geomspace(0.01,20,num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([99.99      , 99.97673082, 99.94585452, 99.8740079 , 99.70682668,\n",
       "       99.31780968, 98.41259895, 96.30624765, 91.40494055, 80.        ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune_percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int(x):\n",
    "    return x*1e8\n",
    "\n",
    "def max_flow_edgelist(master_g, master_capacity=1./10.):\n",
    "    nodes = list(master_g.nodes())\n",
    "    for node in nodes:\n",
    "        if 'conv1' in node and 'layer' not in node:\n",
    "            master_g.add_edge('master', node, weight=master_capacity)\n",
    "    nodes = list(master_g.nodes())\n",
    "    sps = nx.to_scipy_sparse_matrix(master_g)\n",
    "    \n",
    "    sps.data = to_int((1./sps.data)-1).astype('int')\n",
    "    sps.data = sps.data - sps.data.min() + 1\n",
    "    \n",
    "    flow_results = {}\n",
    "    output_nodes = ['Output_0_{}'.format(o) for o in range(10)]\n",
    "\n",
    "    mix = nodes.index('master')\n",
    "    for output_node in output_nodes:\n",
    "        eix = nodes.index(output_node)\n",
    "        mf = maximum_flow(sps, mix, eix)\n",
    "        flow_results[output_node] = mf    \n",
    "        if mf.flow_value > 0:\n",
    "            print(output_node, mf.flow_value, mix, eix)\n",
    "            \n",
    "    edgelist = []\n",
    "    for k,v in flow_results.items():\n",
    "        en = 0\n",
    "        print(k)\n",
    "        ng = nx.from_scipy_sparse_matrix(v.residual)\n",
    "        nns = list(ng.nodes())\n",
    "        nodemap = {nns[i]:nodes[i] for i in range(len(nns))}\n",
    "        ng = nx.relabel_nodes(ng, nodemap)\n",
    "        for edge in ng.edges(data=True):\n",
    "            if edge[2]['weight'] < 0:\n",
    "                en += 1\n",
    "                edgelist.append((edge[0],edge[1]))\n",
    "        print(en)\n",
    "    return edgelist\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, criterion):\n",
    "    EPS = 1e-6\n",
    "    model.train()\n",
    "    for batch_idx, (imgs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "        output = model(imgs)\n",
    "        train_loss = criterion(output, targets)\n",
    "        train_loss.backward()\n",
    "\n",
    "        # Freezing Pruned weights by making their gradients Zero\n",
    "        for name, p in model.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                tensor = p.data.cpu().numpy()\n",
    "                grad_tensor = p.grad.data.cpu().numpy()\n",
    "                grad_tensor = np.where(tensor < EPS, 0, grad_tensor)\n",
    "                p.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "        optimizer.step()\n",
    "        \n",
    "#         if batch_idx % 200000 == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(imgs), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), train_loss.item()))\n",
    "    return train_loss.item()\n",
    "\n",
    "def test(model, test_loader, criterion):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return accuracy, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == 'mnist':\n",
    "    transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    traindataset = datasets.MNIST(data_location, train=True, download=False, transform=transform)\n",
    "    testdataset = datasets.MNIST(data_location, train=False, transform=transform)\n",
    "if dataset_name == 'cifar10':\n",
    "    transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "    traindataset = datasets.CIFAR10(data_location, train=True, download=False, transform=transform)\n",
    "    testdataset = datasets.CIFAR10(data_location, train=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(traindataset, batch_size=60, shuffle=True, num_workers=0, drop_last=False)\n",
    "test_loader = torch.utils.data.DataLoader(testdataset, batch_size=60, shuffle=False, num_workers=0, drop_last=True)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schraterlab/anaconda3/lib/python3.8/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'archs.cifar10.resnet.ResNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv1\n",
      "Layer: layer1.0.conv1\n",
      "Layer: layer1.0.conv2\n",
      "Layer: layer1.0.shortcut\n",
      "Layer: layer1.1.conv1\n",
      "Layer: layer1.1.conv2\n",
      "Layer: layer1.1.shortcut\n",
      "Layer: layer2.0.conv1\n",
      "Layer: layer2.0.conv2\n",
      "Layer: layer2.0.shortcut\n",
      "Layer: layer2.1.conv1\n",
      "Layer: layer2.1.conv2\n",
      "Layer: layer2.1.shortcut\n",
      "Layer: layer3.0.conv1\n",
      "Layer: layer3.0.conv2\n",
      "Layer: layer3.0.shortcut\n",
      "Layer: layer3.1.conv1\n",
      "Layer: layer3.1.conv2\n",
      "Layer: layer3.1.shortcut\n",
      "Layer: layer4.0.conv1\n",
      "Layer: layer4.0.conv2\n",
      "Layer: layer4.0.shortcut\n",
      "Layer: layer4.1.conv1\n",
      "Layer: layer4.1.conv2\n",
      "Layer: layer4.1.shortcut\n",
      "Layer: MaxPool\n",
      "Layer: Linear1\n",
      "Output_0_0 675759621 589322 589314\n",
      "Output_0_1 721438901 589322 589312\n",
      "Output_0_2 750518444 589322 589315\n",
      "Output_0_3 694638474 589322 589316\n",
      "Output_0_4 770222539 589322 589320\n",
      "Output_0_5 651799819 589322 589318\n",
      "Output_0_6 681613968 589322 589313\n"
     ]
    }
   ],
   "source": [
    "# seed, prune_type, prune_percent, epoch, accuracy, loss\n",
    "results = []\n",
    "for seed in seeds:\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "#     model = torch.load(model_loc0.format(model_name, dataset_name, seed))\n",
    "    model = torch.load(isd_loc.format(model_name, dataset_name, seed))\n",
    "    \n",
    "    NNGD = nn_graph.NNGraph(undirected=False)\n",
    "    mc = Mc()\n",
    "    \n",
    "    if percentile_filtration:\n",
    "        ps = []\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'weight' in name and 'bn' not in name:\n",
    "                pnum = param.data.cpu().numpy()\n",
    "                ps.append(pnum.flatten())\n",
    "        ps = np.concatenate(ps)\n",
    "        NNGD.parameter_graph(model, mc.param_info, input_size, ignore_zeros=False, threshold=1./(1.+np.percentile(np.abs(ps), percentile)), verbose=True)\n",
    "    else:\n",
    "        NNGD.parameter_graph(model, mc.param_info, input_size, ignore_zeros=True, verbose=True)\n",
    "    \n",
    "    edgelist = max_flow_edgelist(NNGD.G.copy())\n",
    "    \n",
    "    new_graph = NNGD.G.edge_subgraph(edgelist).copy()\n",
    "    \n",
    "    model_weights = nn_graph.get_weights(model)\n",
    "    model_param_info = nn_graph.append_params(mc.param_info, model_weights)\n",
    "    model_fps = nn_graph.flatten_params(model_param_info).copy()\n",
    "    \n",
    "    NNG = nn_graph.NNGraph()\n",
    "    NNG.G = new_graph.to_undirected()\n",
    "    NNG.update_indices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prune_percent in prune_percents:\n",
    "        \n",
    "    num_edges = model_fps.shape[0]-1\n",
    "\n",
    "    limit = num_edges - int((float(prune_percent)/100.) * num_edges)\n",
    "\n",
    "    model_original = torch.load(isd_loc.format(model_name,dataset_name,seed))\n",
    "\n",
    "    original_weights = nn_graph.get_weights(model_original)\n",
    "    original_param_info = nn_graph.append_params(mc.param_info, original_weights)\n",
    "\n",
    "    fps = nn_graph.flatten_params(original_param_info).copy()\n",
    "    fps2 = fps.copy()\n",
    "    fps2[:] = 0.\n",
    "    fps2[NNG.graph_idx_vec[NNG.adj_vec != 0]] = fps[NNG.graph_idx_vec[NNG.adj_vec != 0]]\n",
    "    num_params = np.sum(fps2 > 0)\n",
    "    print(num_params, limit, num_edges, prune_percent)\n",
    "    if num_params <= limit:\n",
    "        fps2[NNG.graph_idx_vec[NNG.adj_vec != 0]] = fps[NNG.graph_idx_vec[NNG.adj_vec != 0]]\n",
    "        fps2[np.argsort(-np.abs(fps))[:limit]] = fps[np.argsort(-np.abs(fps))[:limit]]\n",
    "#         sargs = np.argsort(-np.abs(fps))\n",
    "#         a = 0\n",
    "#         while 100*np.sum(fps2 != fps)/num_edges > prune_percent :\n",
    "#             fps2[sargs[a]] = fps[sargs[a]]\n",
    "#             a += 1\n",
    "    else:\n",
    "        fps2[:] = 0.\n",
    "        fps2[NNG.graph_idx_vec[NNG.adj_vec != 0][:limit]] = fps[NNG.graph_idx_vec[NNG.adj_vec != 0][:limit]]\n",
    "\n",
    "    print('new percentage', 100*np.sum(fps2 != fps) / num_edges)\n",
    "\n",
    "    ps = nn_graph.inverse_flatten_params(fps2, original_param_info)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#         i = 0\n",
    "#         for seq in model_original.children():\n",
    "#             for layer in seq.children():\n",
    "#                 if isinstance(layer, torch.nn.Conv2d) or isinstance(layer, torch.nn.Linear):\n",
    "#                     layer.data = torch.Tensor(ps[i]).to(device)\n",
    "#                     i += 1\n",
    "    i = 0\n",
    "    for name, param in model_original.named_parameters():\n",
    "        if 'weight' in name and 'bn' not in name and len(param.shape) > 1:\n",
    "            param.data = torch.Tensor(ps[i]).to(device)\n",
    "            i += 1\n",
    "\n",
    "#         optimizer = torch.optim.Adam(model_original.parameters(), lr=1.2e-3, weight_decay=1e-4)\n",
    "    optimizer = torch.optim.SGD(model_original.parameters(), lr=1.2e-3, weight_decay=1e-4, momentum=0.9)\n",
    "    for epoch in range(1,epochs+1):\n",
    "        train(model_original, device, train_loader, optimizer, epoch, criterion)\n",
    "        acc, loss = test(model_original, test_loader, criterion)\n",
    "        print('Seed: {}, Prune Percentage: {}, Epoch: {}, Test Accuracy: {}, Test Loss: {}'.format(seed, prune_percent, epoch, acc, loss))\n",
    "        results.append([seed,'homology',prune_percent,epoch,acc,loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['seed', 'prune_type', 'prune_percent', 'epoch', 'accuracy', 'loss']\n",
    "df = pd.DataFrame(results, columns=col_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch = epochs\n",
    "for seed in seeds:\n",
    "    plt.plot(df[(df['seed'] == seed) & (df['epoch'] == epoch)]['prune_percent'], df[(df['seed'] == seed) & (df['epoch'] == epoch)]['accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sms = []\n",
    "# for seed in seeds:\n",
    "#     sms.append(df[(df['seed'] == seed) & (df['epoch'] == epoch)]['accuracy'].values)\n",
    "# sms = np.array(sms)\n",
    "\n",
    "sms = []\n",
    "for seed in seeds:\n",
    "    dfs = df[df['seed'] == seed]\n",
    "    sms.append(dfs.groupby('prune_percent')['accuracy'].max().values)\n",
    "sms = np.array(sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# seed, prune_type, prune_percent, epoch, accuracy, loss\n",
    "results_threshold = []\n",
    "mc = Mc()\n",
    "for seed in seeds:\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "#     model = torch.load(model_loc0.format(model_name, dataset_name, seed))\n",
    "    model = torch.load(isd_loc.format(model_name, dataset_name, seed))\n",
    "    \n",
    "    model_weights = nn_graph.get_weights(model)\n",
    "    model_param_info = nn_graph.append_params(mc.param_info, model_weights)\n",
    "\n",
    "    model_fps = nn_graph.flatten_params(model_param_info).copy()\n",
    "    \n",
    "    for prune_percent in prune_percents:\n",
    "        \n",
    "        num_edges = model_fps.shape[0]-1\n",
    "        \n",
    "        limit = num_edges - int((float(prune_percent)/100.) * num_edges)\n",
    "        \n",
    "        print(limit, num_edges, prune_percent)\n",
    "\n",
    "        model_original = torch.load(isd_loc.format(model_name,dataset_name,seed))\n",
    "\n",
    "        original_weights = nn_graph.get_weights(model_original)\n",
    "        original_param_info = nn_graph.append_params(mc.param_info, original_weights)\n",
    "\n",
    "        fps = nn_graph.flatten_params(original_param_info).copy()\n",
    "        fps2 = fps.copy()\n",
    "        fps2[:] = 0.\n",
    "        fps2[np.argsort(-np.abs(fps))[:limit]] = fps[np.argsort(-np.abs(fps))[:limit]]\n",
    "        \n",
    "        print('new percentage', np.sum(fps2 != fps) / num_edges)\n",
    "\n",
    "        ps = nn_graph.inverse_flatten_params(fps2, original_param_info)\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "#         i = 0\n",
    "#         for seq in model_original.children():\n",
    "#             for layer in seq.children():\n",
    "#                 if isinstance(layer, torch.nn.Conv2d) or isinstance(layer, torch.nn.Linear):\n",
    "#                     layer.data = torch.Tensor(ps[i]).to(device)\n",
    "#                     i += 1\n",
    "        \n",
    "        i = 0\n",
    "        for name, param in model_original.named_parameters():\n",
    "            if 'weight' in name and 'bn' not in name:\n",
    "                param.data = torch.Tensor(ps[i]).to(device)\n",
    "                i += 1\n",
    "\n",
    "#         optimizer = torch.optim.Adam(model_original.parameters(), lr=1.2e-3, weight_decay=1e-4)\n",
    "        optimizer = torch.optim.SGD(model_original.parameters(), lr=1.2e-3, weight_decay=1e-4, momentum=0.9)\n",
    "        for epoch in range(1,epochs+1):\n",
    "            train(model_original, device, train_loader, optimizer, epoch, criterion)\n",
    "            acc, loss = test(model_original, test_loader, criterion)\n",
    "            print('Seed: {}, Prune Percentage: {}, Epoch: {}, Test Accuracy: {}, Test Loss: {}'.format(seed, prune_percent, epoch, acc, loss))\n",
    "            results_threshold.append([seed,'threshold',prune_percent,epoch,acc,loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seed in seeds:\n",
    "#     dat = np.load('/home/schraterlab/gebhart/projects/LTHT/dumps/lt/{}/{}/{}/prune_all/global/lt_20_bestaccuracy.dat'.format(model_name, dataset_name, seed), allow_pickle=True)\n",
    "#     print(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thresh = pd.DataFrame(results_threshold, columns=col_names)\n",
    "df_thresh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sms_thresh = []\n",
    "# for seed in seeds:\n",
    "#     sms_thresh.append(df_thresh[(df_thresh['seed'] == seed) & (df_thresh['epoch'] == epoch)]['accuracy'].values)\n",
    "# sms_thresh = np.array(sms_thresh)\n",
    "\n",
    "sms_thresh = []\n",
    "for seed in seeds:\n",
    "    dfs = df_thresh[df_thresh['seed'] == seed]\n",
    "    sms_thresh.append(dfs.groupby('prune_percent')['accuracy'].max().values)\n",
    "sms_thresh = np.array(sms_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = df_thresh[(df_thresh['seed'] == seeds[0]) & (df_thresh['epoch'] == epoch)]['prune_percent'].values\n",
    "yvals = sms_thresh.mean(axis=0)\n",
    "ystd = sms_thresh.std(axis=0)\n",
    "plt.plot(xvals,yvals)\n",
    "plt.fill_between(xvals, yvals - ystd, yvals + ystd,\n",
    "                 color='gray', alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = df[(df['seed'] == seeds[0]) & (df['epoch'] == 1)]['prune_percent'].values\n",
    "yvals = np.flip(sms.mean(axis=0))\n",
    "ystd = np.flip(sms.std(axis=0))\n",
    "plt.plot(xvals,yvals,label='Homology Pruning')\n",
    "plt.fill_between(xvals, yvals - ystd, yvals + ystd,\n",
    "                 color='gray', alpha=0.2)\n",
    "\n",
    "xvals = df_thresh[(df_thresh['seed'] == seeds[0]) & (df_thresh['epoch'] == epoch)]['prune_percent'].values\n",
    "yvals = np.flip(sms_thresh.mean(axis=0))\n",
    "ystd = np.flip(sms_thresh.std(axis=0))\n",
    "plt.plot(xvals,yvals,label='Threshold Pruning')\n",
    "plt.fill_between(xvals, yvals - ystd, yvals + ystd,\n",
    "                 color='gray', alpha=0.2)\n",
    "\n",
    "# plt.xscale('log')\n",
    "# plt.gca().invert_xaxis()\n",
    "# plt.plot(1-xvals, yvals)\n",
    "# plt.gca().set_xticklabels(1-plt.gca().get_xticks())\n",
    "\n",
    "plt.title(dataset_name.upper())\n",
    "plt.legend()\n",
    "plt.xlabel('Prune Percentage')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# log log scales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fps = nn_graph.flatten_params(original_param_info).copy()\n",
    "# fps2 = fps.copy()\n",
    "# fps2[:] = 0.\n",
    "# fps2[np.argsort(-np.abs(fps))[:345]] = fps[np.argsort(-np.abs(fps))[:345]]\n",
    "# fps2[NNGD.graph_idx_vec[NNGD.adj_vec != 0]] = fps[NNGD.graph_idx_vec[NNGD.adj_vec != 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
